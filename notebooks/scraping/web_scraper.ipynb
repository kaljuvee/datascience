{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOta/ej+P4f5qblMtq1ZJET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaljuvee/datascience/blob/main/notebooks/scraping/web_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accounting / Outsourcing - LV- 1"
      ],
      "metadata": {
        "id": "zalJRDGUEvJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Send a GET request to the webpage\n",
        "url = \"http://www.lrga.lv/en/registers/accounting-outsourcing-firms\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find all email addresses using regular expressions\n",
        "emails = set(re.findall(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", soup.text))\n",
        "\n",
        "# Create a new Pandas dataframe with the list\n",
        "df = pd.DataFrame({'email': list(emails)})\n",
        "\n",
        "# Write the dataframe to a CSV file\n",
        "df.to_csv('emails_lrga_lv.csv', index=False)"
      ],
      "metadata": {
        "id": "P_5cw55xElup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audiitorikogu"
      ],
      "metadata": {
        "id": "FMp6UEkHGc3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Send GET request to website and parse HTML content\n",
        "url = \"https://www.audiitorkogu.ee/est/audiitorettevotjad\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Extract email addresses from the HTML content\n",
        "email_list = []\n",
        "for a_tag in soup.find_all('a', href=True):\n",
        "    if 'mailto:' in a_tag['href']:\n",
        "        email_list.append(a_tag['href'].replace('mailto:', ''))\n",
        "\n",
        "# Create a pandas dataframe with the email addresses\n",
        "df = pd.DataFrame({'Email': email_list})\n",
        "\n",
        "# Write the dataframe to a CSV file\n",
        "df.to_csv('emails.csv', index=False)"
      ],
      "metadata": {
        "id": "k322PTwLA1PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delfi Media\n",
        "\n",
        "Prompt: Write code to extract all emails from this page https://delfimeedia.ee/kontakt/toimetus/, store in pandas data frame and write to a csv"
      ],
      "metadata": {
        "id": "Hq0FDbkNI9Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Send a GET request to the URL\n",
        "url = 'https://delfimeedia.ee/kontakt/toimetus/'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all email addresses using a regular expression\n",
        "emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', str(soup))\n",
        "\n",
        "# Create a pandas data frame to store the email addresses\n",
        "df = pd.DataFrame({'Email': emails})\n",
        "\n",
        "# Write the data frame to a CSV file\n",
        "df.to_csv('delfi_meedia.csv', index=False)\n"
      ],
      "metadata": {
        "id": "2MAZmDaxJA1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Postimees\n",
        "\n",
        "Write code to extract all emails from this page https://www.postimees.ee/contact, store in pandas data frame and write to a csv"
      ],
      "metadata": {
        "id": "zPx-hUcaLkpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.postimees.ee/contact'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "email_addresses = []\n",
        "for link in soup.find_all('a'):\n",
        "    href = link.get('href')\n",
        "    if href and href.startswith('mailto:'):\n",
        "        email_addresses.append(href[7:])\n",
        "\n",
        "df = pd.DataFrame(email_addresses, columns=['email'])\n",
        "df.to_csv('postimees_emails.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Mjj8pwXlLmFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sirp"
      ],
      "metadata": {
        "id": "ot_vvDh7M7wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a request to the web page\n",
        "url = 'https://www.sirp.ee/kontakt/'\n",
        "response = requests.get(url)\n",
        "\n",
        "# parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# find all email addresses on the page\n",
        "email_list = []\n",
        "for email in soup.find_all('a', href=True):\n",
        "    if 'mailto:' in email['href']:\n",
        "        email_list.append(email['href'][7:])\n",
        "\n",
        "# create a pandas data frame from the list of email addresses\n",
        "df = pd.DataFrame(email_list, columns=['Email'])\n",
        "\n",
        "# write the data frame to a CSV file\n",
        "df.to_csv('sirp_emails.csv', index=False)"
      ],
      "metadata": {
        "id": "W6JjocQQMDAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7rsAXYwNUzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Aripaev\n",
        "\n",
        "Write code to extract all emails from this page https://www.aripaev.ee/staatilised/aripaeva-kontaktid, store in pandas data frame and write to a csv\n",
        "\n"
      ],
      "metadata": {
        "id": "1rVD_XuWUxuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Fetch the webpage content\n",
        "url = 'https://www.aripaev.ee/staatilised/aripaeva-kontaktid'\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Find all email addresses\n",
        "email_tags = soup.select('a[href^=\"mailto:\"]')\n",
        "emails = [email['href'][7:] for email in email_tags]\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "df = pd.DataFrame({'Email': emails})\n",
        "\n",
        "# Save DataFrame to a CSV file\n",
        "df.to_csv('emails.csv', index=False)"
      ],
      "metadata": {
        "id": "iGQXF8mRU643"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Su4EKIIHVKeQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}